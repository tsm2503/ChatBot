{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da6fef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import datetime\n",
    "import transformers \n",
    "from transformers import pipeline\n",
    "import pyaudio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149df8a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Beginning of the AI\n",
    "class ChatBot():\n",
    "    def __init__(self, name):\n",
    "        print(\"----- starting up\", name, \"-----\")\n",
    "        self.name = name\n",
    "\n",
    "    def speech_to_text(self):\n",
    "      recognizer = sr.Recognizer()\n",
    "      with sr.Microphone() as mic:\n",
    "        print(\"listening...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(mic)\n",
    "            self.text = recognizer.recognize_google(audio)\n",
    "            print(\"me -->\", self.text)\n",
    "            return self.text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Mani(AI) --> Couldn't understand audio\")\n",
    "            return \"\"\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Mani(AI) --> Error connecting to Google API; {e}\")\n",
    "            return \"\"\n",
    "            \n",
    "    def wake_up(self, text):\n",
    "       return True if self.name.lower() in text.lower() else False           \n",
    "    @staticmethod\n",
    "    def text_to_speech(text):\n",
    "      print(\"AI --> \", text)\n",
    "      speaker = gTTS(text=text, lang=\"en\", slow=False)\n",
    "      speaker.save(\"res.mp3\")\n",
    "      os.system(\"start res.mp3\")  #if you have a macbook->afplay or for windows use->start\n",
    "      os.remove(\"res.mp3\")\n",
    "    def action_time(self):\n",
    "      return datetime.datetime.now().time().strftime('%H:%M')\n",
    "     #and run the script after adding the above function to the AI class\n",
    "    \n",
    "    \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16dcbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- starting up Mani -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tatta\\Anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me --> hello\n",
      "AI -->  rsation id: 3676a420-28e1-47a2-84f7-195cceedabc3\n",
      "user: hello\n",
      "assistant: Hello! :D\n",
      "listening...\n",
      "me --> how are you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI -->  rsation id: 727d54e2-dc1e-4917-9187-04101b036bc0\n",
      "user: how are you\n",
      "assistant: I'm good, how are you?\n",
      "listening...\n",
      "me --> Inko Shahar resso Apne gane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI -->  rsation id: 3e883970-5dee-44b5-a909-8fe24fcb0bc2\n",
      "user: Inko Shahar resso Apne gane\n",
      "assistant: I'm not sure if you're serious, but I'm pretty sure that's a joke.\n",
      "listening...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ai = ChatBot(name=\"Mani\")\n",
    "    nlp = transformers.pipeline(\"conversational\", model=\"microsoft/DialoGPT-medium\")\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "    ex = True\n",
    "    while ex:\n",
    "        text = ai.speech_to_text()\n",
    "        \n",
    "        # Initialize res outside the wake-up block\n",
    "        res = \"\"\n",
    "\n",
    "        # Wake up\n",
    "        if ai.wake_up(text):\n",
    "            res = \"Hello, I am Mani(AI). What can I do for you?\"\n",
    "                        \n",
    "     ## answering time\n",
    "        elif \"time\" in ai.text:\n",
    "            res = ai.action_time()\n",
    "     ## respond politely\n",
    "        elif any(i in ai.text for i in [\"thank\",\"thanks\"]):\n",
    "            res = np.random.choice(\n",
    "                  [\"you're welcome!\",\"anytime!\",\n",
    "                   \"no problem!\",\"cool!\",\n",
    "                   \"I'm here if you need me!\",\"peace out!\"])\n",
    "      ##exiting chatbot      \n",
    "        elif any(i in ai.text for i in [\"exit\",\"close\"]):\n",
    "            res = np.random.choice([\"Tata\",\"Have a good day\",\"Bye\",\"Goodbye\",\"Hope to meet soon\",\"peace out!\"])\n",
    "            ex=False \n",
    "        else:   \n",
    "            if ai.text==\"Couldn't understand audio\":\n",
    "                res=\"Sorry, come again?\"\n",
    "            else:\n",
    "                chat = nlp(transformers.Conversation(ai.text), pad_token_id=50256)\n",
    "                res = str(chat)\n",
    "                res = res[res.find(\"bot >> \")+6:].strip()\n",
    "\n",
    "        if res:\n",
    "              ai.text_to_speech(res)\n",
    "    print(\"----- Closing down Mani -----\")    \n",
    "                \n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
